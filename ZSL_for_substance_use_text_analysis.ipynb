{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dnc2nEHGHjxy"
      },
      "source": [
        "# Tutorial: Zero-Shot Learning For Substance Use Text Analysis\n",
        "\n",
        "In this tutorial we are going to implement Zero-Shot Learning (ZSL) using the BART (Bidirectional Auto-Regressive Transformer) model. This notebook is available in two forms:\n",
        "\n",
        "1. [Online (Google Colab)](https://colab.research.google.com/github/ltu-capr/zsl-text-tutorial/blob/master/ZSL_for_substance_use_text_analysis.ipynb): For experimenting on Google's free platform without installing anything on your computer.\n",
        "2. [Offline (Jupyter Notebook)](https://github.com/ltu-capr/zsl-text-tutorial): For experimenting locally on your own computer. This takes some additional setup, but is the best option for working with sensitive data.\n",
        "\n",
        "To run the code in a cell, click inside it and then press Ctrl + Enter.\n",
        "\n",
        "*The ZSL model at the core of this notebook runs much faster with graphics processing unit (GPU) acceleration. If you are in Google Colab, you can enable GPU accleration in the settings by going to Runtime > Change runtime type > Hardware accelerator (select \"GPU\").*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "edeZK6NdhMHR"
      },
      "source": [
        "## Example scenario: cannabis legalisation support\n",
        "\n",
        "For this task, we classify cannabis-related social media posts using two labels: pro-legalisation, and anti-legalisation."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2rxMlU9YIESN"
      },
      "source": [
        "### Cell 0: Install software package requirements\n",
        "\n",
        "- Pandas is used to load and save data in CSV (comma separated value) format.\n",
        "- PyTorch and Transformers are used to run the model.\n",
        "- tqdm is used to show progress bars."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fGddJISHflf"
      },
      "outputs": [],
      "source": [
        "!pip install pandas torch transformers tqdm"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K0yoIv53IhbU"
      },
      "source": [
        "### Cell 1: Import essential modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO9lgHWIIo53"
      },
      "outputs": [],
      "source": [
        "import os.path\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import pipeline\n",
        "from transformers.pipelines.pt_utils import KeyDataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gBL5du9QJAEQ"
      },
      "source": [
        "### Cell 2: Load the \"cannabis legalisation\" dataset\n",
        "\n",
        "This sample data was generated using ChatGPT, but the methododology presented here works just as well with real data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJJrVOVVJJ4l"
      },
      "outputs": [],
      "source": [
        "# Load the CSV file containing our dataset.\n",
        "# Here we are giving the URL for a sample file that we've made publicly\n",
        "# available on the Internet.\n",
        "data_location = 'https://raw.githubusercontent.com/ltu-capr/zsl-text-tutorial/master/Data/cannabis_legalisation.csv'\n",
        "dataframe = pd.read_csv(data_location)\n",
        "input_dataset = KeyDataset(dataframe.to_dict('records'), key='text')\n",
        "\n",
        "# Display the first 5 text examples from the dataset.\n",
        "for n, text in zip(range(1, 6), input_dataset):\n",
        "    print(f'{n}. {text}')\n",
        "print('   ...')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FQBW9nBCOrtZ"
      },
      "source": [
        "### Cell 3: Initialise the BART model\n",
        "\n",
        "Initialise the BART model for use in performing zero-shot classification. It may take a while for the model to download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxawqYw_O2OC"
      },
      "outputs": [],
      "source": [
        "# Check to see whether GPU acceleration is available.\n",
        "if torch.cuda.is_available():\n",
        "    device = 0\n",
        "else:\n",
        "    device = -1\n",
        "\n",
        "# Initialise the BART model.\n",
        "model_type = 'facebook/bart-large-mnli'\n",
        "classifier = pipeline('zero-shot-classification', model=model_type, device=device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N3ellE43PKuk"
      },
      "source": [
        "### Cell 4: Initialise classification labels and make model predictions\n",
        "\n",
        "In order to perform classification we must nominate candidate labels for the model to choose between. In this scenario we have two labels, but you can choose as many labels as you need."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTWc-Nt7PCIj"
      },
      "outputs": [],
      "source": [
        "# Here we specify the label options that the model will choose from.\n",
        "candidate_labels = ['pro-legalisation', 'anti-legalisation']\n",
        "\n",
        "# Start the classification pipeline.\n",
        "classifier_outputs = classifier(input_dataset, candidate_labels, batch_size=4)\n",
        "\n",
        "# Generate prediction results.\n",
        "all_results = []\n",
        "for result in tqdm(classifier_outputs, total=len(input_dataset)):\n",
        "    # Display the first 5 results as the model is running.\n",
        "    if len(all_results) < 5:\n",
        "        text = result['sequence']\n",
        "        labels_with_scores = [\n",
        "            f'{label} ({score:.2%})'\n",
        "            for label, score in zip(result['labels'], result['scores'])\n",
        "        ]\n",
        "        tqdm.write('')\n",
        "        tqdm.write(f'Input text:         {text}')\n",
        "        tqdm.write(f'Model predictions:  {\", \".join(labels_with_scores)}')\n",
        "\n",
        "    # Compile a list of all prediction results.\n",
        "    all_results.append(result)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_4oIK0tSTMmN"
      },
      "source": [
        "### Cell 5: Save the model predictions\n",
        "\n",
        "This code prepares an output CSV file containing model predictions which can be used for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PR0md2_TT4G"
      },
      "outputs": [],
      "source": [
        "def save_model_predictions(file_name, dataframe, all_results, candidate_labels):\n",
        "    # Arrange the results in tabular form with neat columns.\n",
        "    rows = []\n",
        "    for result in all_results:\n",
        "        labels = result['labels']\n",
        "        scores_as_percentages = [round(score * 100, 2) for score in result['scores']]\n",
        "        row = {'text': result['sequence'], **dict(zip(labels, scores_as_percentages))}\n",
        "        rows.append(row)\n",
        "    results_df = pd.DataFrame(rows, columns=['text', *candidate_labels])\n",
        "    results_df['predicted_label'] = results_df[candidate_labels].idxmax(axis=1)\n",
        "\n",
        "    # Append the hand-annotated ground truth column (if it exists).\n",
        "    if 'hand_annotated' in dataframe.columns:\n",
        "        results_df['hand_annotated'] = dataframe['hand_annotated']\n",
        "\n",
        "    # Save output to a CSV file.\n",
        "    os.makedirs('Outputs', exist_ok=True)\n",
        "    output_file_name = os.path.join('Outputs', file_name)\n",
        "    results_df.to_csv(output_file_name, index=False)\n",
        "\n",
        "    try:\n",
        "        # If we are on Google Colab, download the results.\n",
        "        from google.colab import files\n",
        "        files.download(output_file_name)\n",
        "    except ModuleNotFoundError:\n",
        "        # If we are not on Google Colab, show the output file location.\n",
        "        print('Output file saved:')\n",
        "        print(os.path.abspath(output_file_name))\n",
        "\n",
        "\n",
        "save_model_predictions('cannabis_legalisation_predictions.csv',\n",
        "                       dataframe, all_results, candidate_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TTA5ZWrkhuq9"
      },
      "source": [
        "### Cell 6: Measure the accuracy of model predictions (optional)\n",
        "\n",
        "Zero-shot learning does not require hand-annotated labels to generate predictions, but they can be use to validate the model's accuracy. Here we compare the model's outputs with hand-annotated (ground truth) labels. If you don't have hand-annotated labels for your data, skip this step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95CCY_pmh6PO"
      },
      "outputs": [],
      "source": [
        "correct_count = 0\n",
        "total_count = 0\n",
        "\n",
        "for result, ground_truth in zip(all_results, dataframe['hand_annotated']):\n",
        "    total_count += 1\n",
        "    correct_count += result['labels'][0] == ground_truth\n",
        "\n",
        "accuracy = correct_count / total_count\n",
        "print(f'Accuracy: {accuracy:.2%}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M0GDeQfZFbMO"
      },
      "source": [
        "## Try your own analysis\n",
        "\n",
        "*Ensure that you have run through the \"Example scenario\" first, as this code makes use of the classifier we initialised in that part of the tutorial.*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sNWCMjJjGZRx"
      },
      "source": [
        "### Simple playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnO1aetYFeIx"
      },
      "outputs": [],
      "source": [
        "# Try your own example by modifying the input text and candidate labels.\n",
        "\n",
        "# Put the text that you want the model to classify here.\n",
        "input_text = [\n",
        "    'Minimum unit pricing is ridiculous and should be abolished. Big government should not tell me how much a drink should cost.',\n",
        "]\n",
        "\n",
        "# Put the options for the model to choose from here.\n",
        "candidate_labels = [\n",
        "    'supports minimum unit pricing',\n",
        "    'does not support minimum unit pricing',\n",
        "]\n",
        "\n",
        "classifier(input_text, candidate_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vv482xRC-3H6"
      },
      "source": [
        "### Bring your own CSV\n",
        "\n",
        "Instead of entering your input text directly into the code as above, you can instead supply your own data as a CSV file. This makes it easier to experiment with much larger datasets. To do so, ensure that your file has a column called \"text\" with one example per row. You can create a file like this in Microsoft Excel by saving as a `.csv` file.\n",
        "\n",
        "When running the following cell, you will be asked to select/input your data file using widgets that appear directly below the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "if79uKGc_Sun"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # If we are on Google Colab, show an upload widget.\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        data_location = list(uploaded.keys())[0]\n",
        "    else:\n",
        "        data_location = ''\n",
        "except ModuleNotFoundError:\n",
        "    # If we are not on Google Colab, ask for the name of the file.\n",
        "    data_location = input('Please enter the name of the file '\n",
        "                          '(e.g. Data/cannabis_legalisation.csv)\\n> ')\n",
        "\n",
        "# Check whether the file exists.\n",
        "if not os.path.isfile(data_location):\n",
        "    print(f'File not found: {data_location}')\n",
        "    print('Please run this cell again.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_w4XbAXAOY7"
      },
      "outputs": [],
      "source": [
        "# Read the input data.\n",
        "dataframe = pd.read_csv(data_location)\n",
        "input_dataset = KeyDataset(dataframe.to_dict('records'), key='text')\n",
        "\n",
        "# Show the first 5 text examples.\n",
        "for n, text in zip(range(1, 6), input_dataset):\n",
        "    print(f'{n}. {text}')\n",
        "print('   ...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWqCfPK8BwKi"
      },
      "outputs": [],
      "source": [
        "# Here we specify the label options that the model will choose from.\n",
        "# Make sure that you update these options to suit your data and experiment\n",
        "# with different wordings.\n",
        "candidate_labels = ['pro-legalisation', 'anti-legalisation']\n",
        "\n",
        "# Start the classification pipeline.\n",
        "classifier_outputs = classifier(input_dataset, candidate_labels, batch_size=4)\n",
        "\n",
        "# Generate prediction results.\n",
        "all_results = []\n",
        "for result in tqdm(classifier_outputs, total=len(input_dataset)):\n",
        "    all_results.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcOm6CFYCLKC"
      },
      "outputs": [],
      "source": [
        "# Save output to a CSV file.\n",
        "save_model_predictions('predictions.csv', dataframe, all_results, candidate_labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
